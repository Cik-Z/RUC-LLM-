# LLM_rerank.py
"""
åŸºäº Hybrid åˆç­› + DeepSeek LLM é‡æ’çš„æ£€ç´¢æ¨¡å—ã€‚
ä¿®å¤ç‰ˆï¼šè§£å†³äº† ImportError: cannot import name 'get_lucene_searcher'
"""

import os
import json
from typing import List, Dict
from openai import OpenAI

# å¯¼å…¥æ¨¡å—
from hybrid_search import hybrid_search
from bm_search import get_searcher

# é…ç½® DeepSeek
client = OpenAI(
    api_key=os.getenv("DEEPSEEK_API_KEY"),
    base_url="https://api.deepseek.com/v1"
)

def _build_rerank_prompt(query: str, docs: List[Dict]) -> str:
    """æ„é€ ç»™ LLM çš„æ‰“åˆ†æç¤ºè¯"""
    lines = []
    lines.append("ä½ æ˜¯ä¸€ä¸ªæœç´¢å¼•æ“çš„ç›¸å…³æ€§è¯„ä¼°åŠ©æ‰‹ã€‚")
    lines.append("è¯·ä¸ºä»¥ä¸‹æ–‡æ¡£æ‰“åˆ†ï¼ˆ0-5åˆ†ï¼‰ï¼Œ0=æ— å…³ï¼Œ5=é«˜åº¦ç›¸å…³ã€‚")
    lines.append(f"ç”¨æˆ·æŸ¥è¯¢ï¼š{query}\n")
    lines.append("å€™é€‰æ–‡æ¡£åˆ—è¡¨ï¼š")

    for i, d in enumerate(docs, 1):
        # æˆªå–å‰ 300 å­—
        snippet = d["contents"].replace("\n", " ")[:300]
        lines.append(f"[DOC_{i}] docid={d['docid']}")
        lines.append(f"å†…å®¹: {snippet}\n")

    lines.append("è¯·åªè¾“å‡º JSON æ•°ç»„ï¼Œæ ¼å¼ï¼š")
    lines.append('[{"docid": "...", "score": 0-5}, ...]')
    return "\n".join(lines)

def _parse_llm_json(text: str) -> List[Dict]:
    """è§£æ LLM è¿”å›çš„ JSON"""
    try:
        text = text.strip()
        # æ¸…ç† markdown æ ‡è®°
        if text.startswith("```"):
            text = text.split("\n", 1)[-1].rsplit("\n", 1)[0]
        
        start = text.find("[")
        end = text.rfind("]")
        if start != -1 and end != -1:
            return json.loads(text[start:end+1])
        return []
    except:
        return []

def llm_rerank(query: str, top_k_candidate: int = 50, top_k_final: int = 10, alpha: float = 0.7) -> List[Dict]:
    """
    Hybrid Search -> LLM Rerank
    """
    # 1. åˆç­› (Hybrid)
    hybrid_hits = hybrid_search(query, top_k=top_k_candidate, k=60)

    # 2. ğŸ”¥ã€æ ¸å¿ƒä¿®å¤ã€‘åˆ›å»ºä¸€æ¬¡ Searcherï¼Œè€Œä¸æ˜¯åœ¨å¾ªç¯é‡Œåˆ›å»º
    searcher = get_searcher()
    
    docs = []
    for h in hybrid_hits:
        try:
            # 3. æŸ¥åŸæ–‡
            doc = searcher.doc(h["docid"])
            if doc:
                raw = json.loads(doc.raw())
                docs.append({
                    "docid": h["docid"],
                    "url": raw.get("url", ""),
                    "contents": raw.get("contents", ""),
                    "hybrid_score": h["score"]
                })
        except Exception as e:
            print(f"âš ï¸ æ–‡æ¡£è¯»å–å¤±è´¥: {h['docid']} - {e}")
            continue

    if not docs:
        return []

    # 4. è°ƒç”¨ LLM è¿›è¡Œé‡æ’
    prompt = _build_rerank_prompt(query, docs)
    
    try:
        resp = client.chat.completions.create(
            model="deepseek-chat",
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸¥è°¨çš„æœç´¢ç›¸å…³æ€§æ‰“åˆ†å™¨ï¼Œåªè¾“å‡ºJSONã€‚"},
                {"role": "user", "content": prompt},
            ],
            temperature=0,
        )
        scored_list = _parse_llm_json(resp.choices[0].message.content)
    except Exception as e:
        print(f"âŒ LLM Rerank å¤±è´¥: {e}")
        scored_list = []

    # 5. åˆ†æ•°èåˆ (LLM Score + Hybrid Score)
    score_map = {item["docid"]: float(item["score"]) for item in scored_list if "docid" in item and "score" in item}

    reranked = []
    for d in docs:
        docid = d["docid"]
        llm_score = score_map.get(docid, 0.0)
        # ç»¼åˆåˆ†ï¼šä¸»è¦çœ‹ LLMï¼ŒHybrid å¾®è°ƒ
        final_score = llm_score + 0.1 * d["hybrid_score"]
        
        reranked.append({
            "docid": docid,
            "url": d["url"],
            "contents": d["contents"],
            "final_score": final_score
        })

    # 6. æ’åºå¹¶è¿”å› Top K
    reranked.sort(key=lambda x: x["final_score"], reverse=True)
    return reranked[:top_k_final]