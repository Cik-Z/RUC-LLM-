# rag_qa.py
import os
import json
from openai import OpenAI
from hybrid_search import hybrid_search 
from bm_search import get_searcher # å¿…é¡»å¤ç”¨è¿™ä¸ªæ­£ç¡®çš„ searcher

# é…ç½® DeepSeek å®¢æˆ·ç«¯
client = OpenAI(
    api_key=os.getenv("DEEPSEEK_API_KEY"),
    base_url="https://api.deepseek.com/v1"
)

def build_prompt(query: str, context_docs: list) -> str:
    """æ„å»ºç»™å¤§æ¨¡å‹çš„æç¤ºè¯ - ä¼˜åŒ–ç‰ˆ"""
    context_str = ""
    for i, doc in enumerate(context_docs, 1):
        # ç¨å¾®å¢åŠ ä¸€ç‚¹é•¿åº¦ï¼Œ350å­—
        content = doc.get("contents", "")[:350].replace("\n", " ")
        context_str += f"[å‚è€ƒæ–‡æ¡£{i}]: {content}\n\n"

    # ğŸ”¥ ä¿®æ”¹æ ¸å¿ƒï¼šè®© AI æ—¢èƒ½å›ç­”é—®é¢˜ï¼Œä¹Ÿèƒ½æ€»ç»“å…³é”®è¯
    prompt = f"""
    ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½æ ¡å›­åŠ©æ‰‹ã€‚è¯·å‚è€ƒä¸‹é¢çš„ã€å‚è€ƒèµ„æ–™ã€‘æ¥å¤„ç†ç”¨æˆ·çš„ã€è¾“å…¥ã€‘ã€‚

    ä»»åŠ¡è¦æ±‚ï¼š
    1. å¦‚æœã€è¾“å…¥ã€‘æ˜¯ä¸€ä¸ªå…·ä½“é—®é¢˜ï¼ˆå¦‚â€œå­¦é™¢åœ¨å“ªï¼Ÿâ€ï¼‰ï¼Œè¯·ç›´æ¥å›ç­”ã€‚
    2. å¦‚æœã€è¾“å…¥ã€‘åªæ˜¯ä¸€ä¸ªå…³é”®è¯ï¼ˆå¦‚â€œäººå·¥æ™ºèƒ½â€ï¼‰ï¼Œè¯·æ ¹æ®å‚è€ƒèµ„æ–™ç”Ÿæˆä¸€æ®µç®€çŸ­çš„æ‘˜è¦æˆ–ä»‹ç»ã€‚
    3. è¿™æ˜¯ä¸€ä¸ªæ£€ç´¢å¢å¼ºç³»ç»Ÿï¼Œè¯·**å®Œå…¨åŸºäº**ã€å‚è€ƒèµ„æ–™ã€‘å›ç­”ã€‚

    ã€å‚è€ƒèµ„æ–™ã€‘ï¼š
    {context_str}

    ã€è¾“å…¥ã€‘ï¼š{query}
    """
    return prompt

def rag_answer(query: str, top_k: int = 5) -> str:
    """
    RAG æµç¨‹
    """
    print(f"ğŸ¤– [RAG] æ­£åœ¨æ€è€ƒ: {query}")
    
    # 1. æ£€ç´¢ (å¤ç”¨ hybrid_search)
    hits = hybrid_search(query, top_k=top_k)
    searcher = get_searcher()
    
    context_docs = []
    for h in hits:
        try:
            # âœ… å¿…é¡»ä½¿ç”¨æ­£ç¡®çš„ .doc().raw() å†™æ³•
            doc = searcher.doc(h["docid"])
            if doc:
                raw = json.loads(doc.raw())
                context_docs.append({
                    "contents": raw.get("contents", ""),
                    "url": raw.get("url", "")
                })
        except Exception as e:
            print(f"âš ï¸ æ–‡æ¡£è§£æè·³è¿‡: {e}")
            continue

    if not context_docs:
        return "æŠ±æ­‰ï¼Œæ²¡æœ‰æ‰¾åˆ°ç›¸å…³çš„æ ¡å›­èµ„æ–™ï¼Œæ— æ³•å›ç­”æ‚¨çš„é—®é¢˜ã€‚"

    # 2. æ„å»º Prompt
    prompt = build_prompt(query, context_docs)
    
    # ğŸ”¥ è°ƒè¯•æ‰“å°ï¼šè®©ä½ åœ¨åå°çœ‹åˆ°åˆ°åº•å‘ç»™äº† AI ä»€ä¹ˆ
    print("---------------- PROMPT ----------------")
    print(prompt[:500] + "...\n(æç¤ºè¯è¿‡é•¿å·²æˆªæ–­)")
    print("----------------------------------------")

    # 3. è°ƒç”¨ DeepSeek
    try:
        response = client.chat.completions.create(
            model="deepseek-chat",
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¹äºåŠ©äººçš„æ ¡å›­é—®ç­”åŠ©æ‰‹ã€‚å›ç­”è¦ç®€æ´ï¼Œè¯­æ°”äº²åˆ‡ã€‚"},
                {"role": "user", "content": prompt},
            ],
            temperature=0.3, 
            stream=False # æš‚æ—¶ä¸ç”¨æµå¼ï¼Œç®€å•ç‚¹
        )
        answer = response.choices[0].message.content
        return answer
    except Exception as e:
        print(f"âŒ LLM è°ƒç”¨å‡ºé”™: {e}")
        return "æŠ±æ­‰ï¼ŒAI å¤§è„‘æš‚æ—¶çŸ­è·¯äº†ï¼Œè¯·æ£€æŸ¥ API Key æˆ–ç½‘ç»œã€‚"

if __name__ == "__main__":
    # æœ¬åœ°æµ‹è¯•
    print(rag_answer("äººå·¥æ™ºèƒ½"))